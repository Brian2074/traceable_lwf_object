# ğŸš€ Multi-Machine Federated Learning Deployment Guide

## Architecture

| Machine | Role              | RAM   | GPU       |
|---------|-------------------|-------|-----------|
| æœ¬æ©Ÿ A  | Server + Client 0 | 32 GB | RTX 2060  |
| é›»è…¦ B  | Client 1          | 16 GB | RTX 2060  |
| é›»è…¦ C  | Client 2          | 16 GB | RTX 2060  |

> [!IMPORTANT]
> è«‹å…ˆåœ¨æœ¬æ©Ÿç”¨ `ip addr` æˆ– `hostname -I` æŸ¥å‡ºæœ¬æ©Ÿçš„ LAN IPï¼ˆä¾‹å¦‚ `192.168.1.100`ï¼‰ï¼Œä¸‹é¢çš„æŒ‡ä»¤éƒ½ç”¨é€™å€‹ IPã€‚

---

## Step 0ï¼šåœ¨ä¸‰å°é›»è…¦ä¸Šéƒ½æº–å‚™å¥½å°ˆæ¡ˆ

```bash
# åœ¨æ¯ä¸€å°é›»è…¦ä¸Š
git clone <your-repo-url> traceable_lwf_object
cd traceable_lwf_object
```

---

## Step 1ï¼šåœ¨ä¸‰å°é›»è…¦ä¸Šç”¢ç”Ÿè³‡æ–™é›†

```bash
# å®‰è£ python dependencies (æˆ–ç”¨ Docker å…§å»º)
pip install -r requirements.txt

# ä¸‹è¼‰ + è½‰æ›è³‡æ–™é›†
python tools/hf2yolo.py

# åˆ‡æˆ 3 å€‹ Non-IID åˆ†ç‰‡
python tools/split_non_iid.py --data_dir datasets/spscd_coco_yolo --clients 3 --alpha 0.5
```

> [!TIP]
> å¦‚æœç¶²è·¯æ…¢ï¼Œå¯ä»¥ç›´æ¥å¾æœ¬æ©Ÿç”¨ `scp -r datasets/ user@é›»è…¦B:~/traceable_lwf_object/` æŠŠè³‡æ–™å‚³éå»ã€‚

---

## Step 2ï¼šåœ¨ä¸‰å°é›»è…¦ä¸Š Build Docker Image

```bash
cd traceable_lwf_object
docker build -t fedrep-yolo:latest -f docker/Dockerfile .
```

---

## Step 3ï¼šå•Ÿå‹• Serverï¼ˆæœ¬æ©Ÿ Aï¼‰

```bash
cd traceable_lwf_object/docker

NUM_CLIENTS=3 \
ROUNDS=10 \
TASKS=1 \
TASKS_EPOCH=3 \
EXP_NAME=distributed_3client \
  docker compose -f server-compose.yml up
```

Server æœƒé–‹å§‹ç›£è½ `0.0.0.0:8080`ï¼Œç­‰å¾… 3 å€‹ Client é€£å…¥ã€‚

---

## Step 4ï¼šå•Ÿå‹• Client 0ï¼ˆæœ¬æ©Ÿ Aï¼Œé–‹å¦ä¸€å€‹çµ‚ç«¯æ©Ÿï¼‰

```bash
cd traceable_lwf_object/docker

SERVER_ADDRESS=<æœ¬æ©ŸIP>:8080 \
CLIENT_ID=0 \
BATCH_SIZE=16 \
BODY_EPOCHS=5 \
HEAD_EPOCHS=5 \
EXP_NAME=distributed_3client \
  docker compose -f client-compose.yml up
```

---

## Step 5ï¼šå•Ÿå‹• Client 1ï¼ˆé›»è…¦ Bï¼‰

```bash
cd traceable_lwf_object/docker

SERVER_ADDRESS=<æœ¬æ©ŸIP>:8080 \
CLIENT_ID=1 \
BATCH_SIZE=16 \
BODY_EPOCHS=5 \
HEAD_EPOCHS=5 \
EXP_NAME=distributed_3client \
  docker compose -f client-compose.yml up
```

---

## Step 6ï¼šå•Ÿå‹• Client 2ï¼ˆé›»è…¦ Cï¼‰

```bash
cd traceable_lwf_object/docker

SERVER_ADDRESS=<æœ¬æ©ŸIP>:8080 \
CLIENT_ID=2 \
BATCH_SIZE=16 \
BODY_EPOCHS=5 \
HEAD_EPOCHS=5 \
EXP_NAME=distributed_3client \
  docker compose -f client-compose.yml up
```

---

## ğŸ‰ é–‹å§‹è¨“ç·´

ç•¶ 3 å€‹ Client å…¨éƒ¨é€£ä¸Š Server å¾Œï¼ŒFlower æœƒè‡ªå‹•é–‹å§‹ç¬¬ä¸€è¼ª FedRep è¨“ç·´ï¼

ä½ æœƒåœ¨ Server çµ‚ç«¯æ©Ÿçœ‹åˆ°ï¼š
```
Round 1 â†’ Task 1 (10 classes), 3 clients
```

æ¯å€‹ Client çš„è¨“ç·´ Log æœƒç›´æ¥è¼¸å‡ºåœ¨å„è‡ªçš„çµ‚ç«¯æ©Ÿè£¡ã€‚

---

## Troubleshooting

| å•é¡Œ | è§£æ³• |
|------|------|
| Client é€£ä¸ä¸Š Server | ç¢ºèªé˜²ç«ç‰†æœ‰é–‹ port 8080ï¼š`sudo ufw allow 8080` |
| CUDA out of memory | æŠŠ `BATCH_SIZE` é™åˆ° `8` |
| 16GB RAM è¢« OOM Kill | å·²å…§å»º `_cleanup_trainer()` é˜²è­·ï¼Œä¸æ‡‰è©²ç™¼ç”Ÿ |
| Docker GPU æ‰¾ä¸åˆ° | ç¢ºèª `nvidia-container-toolkit` å·²å®‰è£ |
